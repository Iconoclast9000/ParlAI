{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Iconoclast9000/ParlAI/blob/main/gptlocal.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OBL0jXoQDiLA"
      },
      "outputs": [],
      "source": [
        "! nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L0f2DQj39_uL",
        "outputId": "ca551c1c-a5e1-4f9f-d17f-6d8d9b7f738f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Colab/localGPT\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/MyDrive/Colab/localGPT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VvSSRG8QYs01"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/PromtEngineer/localGPT.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "p1DakC0w-qVw",
        "outputId": "3f09754a-51c7-45f0-aef4-7eecaff5947a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ignoring protobuf: markers 'sys_platform == \"darwin\" and platform_machine != \"arm64\"' don't match your environment\n",
            "Ignoring protobuf: markers 'sys_platform == \"darwin\" and platform_machine == \"arm64\"' don't match your environment\n",
            "Collecting langchain==0.0.191 (from -r requirements.txt (line 2))\n",
            "  Downloading langchain-0.0.191-py3-none-any.whl (993 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m993.7/993.7 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting chromadb==0.3.22 (from -r requirements.txt (line 3))\n",
            "  Downloading chromadb-0.3.22-py3-none-any.whl (69 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.2/69.2 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting llama-cpp-python==0.1.48 (from -r requirements.txt (line 4))\n",
            "  Downloading llama_cpp_python-0.1.48.tar.gz (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pdfminer.six==20221105 (from -r requirements.txt (line 5))\n",
            "  Downloading pdfminer.six-20221105-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting InstructorEmbedding (from -r requirements.txt (line 6))\n",
            "  Downloading InstructorEmbedding-1.0.1-py2.py3-none-any.whl (19 kB)\n",
            "Collecting sentence-transformers (from -r requirements.txt (line 7))\n",
            "  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting faiss-cpu (from -r requirements.txt (line 8))\n",
            "  Downloading faiss_cpu-1.7.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.6/17.6 MB\u001b[0m \u001b[31m48.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting huggingface_hub (from -r requirements.txt (line 9))\n",
            "  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting transformers (from -r requirements.txt (line 10))\n",
            "  Downloading transformers-4.31.0-py3-none-any.whl (7.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m63.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting protobuf==3.20.0 (from -r requirements.txt (line 11))\n",
            "  Downloading protobuf-3.20.0-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m44.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting auto-gptq (from -r requirements.txt (line 14))\n",
            "  Downloading auto_gptq-0.3.2.tar.gz (63 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.5/63.5 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Discarding \u001b[4;34mhttps://files.pythonhosted.org/packages/1b/79/5a3a7d877a9b0a72f528e9977ec65cdb9fad800fa4f5110f87f2acaaf6fe/auto_gptq-0.3.2.tar.gz (from https://pypi.org/simple/auto-gptq/) (requires-python:>=3.8.0)\u001b[0m: \u001b[33mRequested auto-gptq from https://files.pythonhosted.org/packages/1b/79/5a3a7d877a9b0a72f528e9977ec65cdb9fad800fa4f5110f87f2acaaf6fe/auto_gptq-0.3.2.tar.gz (from -r requirements.txt (line 14)) has inconsistent version: expected '0.3.2', but metadata has '0.3.2+cu118'\u001b[0m\n",
            "  Downloading auto_gptq-0.3.1.tar.gz (63 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.5/63.5 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Discarding \u001b[4;34mhttps://files.pythonhosted.org/packages/3f/5c/28d57f833498e014e9d066ea0199a503b5e59d4c8e8e701a460223e143da/auto_gptq-0.3.1.tar.gz (from https://pypi.org/simple/auto-gptq/) (requires-python:>=3.8.0)\u001b[0m: \u001b[33mRequested auto-gptq from https://files.pythonhosted.org/packages/3f/5c/28d57f833498e014e9d066ea0199a503b5e59d4c8e8e701a460223e143da/auto_gptq-0.3.1.tar.gz (from -r requirements.txt (line 14)) has inconsistent version: expected '0.3.1', but metadata has '0.3.1+cu1180'\u001b[0m\n",
            "  Downloading auto_gptq-0.3.0.tar.gz (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting urllib3==1.26.6 (from -r requirements.txt (line 17))\n",
            "  Downloading urllib3-1.26.6-py2.py3-none-any.whl (138 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.5/138.5 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting accelerate (from -r requirements.txt (line 18))\n",
            "  Downloading accelerate-0.21.0-py3-none-any.whl (244 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.2/244.2 kB\u001b[0m \u001b[31m25.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting bitsandbytes (from -r requirements.txt (line 19))\n",
            "  Downloading bitsandbytes-0.41.1-py3-none-any.whl (92.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.6/92.6 MB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 20)) (8.1.6)\n",
            "Requirement already satisfied: flask in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 21)) (2.2.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 22)) (2.31.0)\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 25)) (3.0.10)\n",
            "Requirement already satisfied: PyYAML>=5.4.1 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.191->-r requirements.txt (line 2)) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.191->-r requirements.txt (line 2)) (2.0.19)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.191->-r requirements.txt (line 2)) (3.8.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.191->-r requirements.txt (line 2)) (4.0.2)\n",
            "Collecting dataclasses-json<0.6.0,>=0.5.7 (from langchain==0.0.191->-r requirements.txt (line 2))\n",
            "  Downloading dataclasses_json-0.5.14-py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.191->-r requirements.txt (line 2)) (2.8.4)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.191->-r requirements.txt (line 2)) (1.23.5)\n",
            "Collecting openapi-schema-pydantic<2.0,>=1.2 (from langchain==0.0.191->-r requirements.txt (line 2))\n",
            "  Downloading openapi_schema_pydantic-1.2.4-py3-none-any.whl (90 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.191->-r requirements.txt (line 2)) (1.10.12)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.191->-r requirements.txt (line 2)) (8.2.2)\n",
            "Requirement already satisfied: pandas>=1.3 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.3.22->-r requirements.txt (line 3)) (1.5.3)\n",
            "Collecting hnswlib>=0.7 (from chromadb==0.3.22->-r requirements.txt (line 3))\n",
            "  Downloading hnswlib-0.7.0.tar.gz (33 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting clickhouse-connect>=0.5.7 (from chromadb==0.3.22->-r requirements.txt (line 3))\n",
            "  Downloading clickhouse_connect-0.6.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (966 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m966.2/966.2 kB\u001b[0m \u001b[31m62.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: duckdb>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.3.22->-r requirements.txt (line 3)) (0.8.1)\n",
            "Collecting fastapi>=0.85.1 (from chromadb==0.3.22->-r requirements.txt (line 3))\n",
            "  Downloading fastapi-0.101.0-py3-none-any.whl (65 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.7/65.7 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting uvicorn[standard]>=0.18.3 (from chromadb==0.3.22->-r requirements.txt (line 3))\n",
            "  Downloading uvicorn-0.23.2-py3-none-any.whl (59 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.5/59.5 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting posthog>=2.4.0 (from chromadb==0.3.22->-r requirements.txt (line 3))\n",
            "  Downloading posthog-3.0.1-py2.py3-none-any.whl (37 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.3.22->-r requirements.txt (line 3)) (4.7.1)\n",
            "Requirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six==20221105->-r requirements.txt (line 5)) (3.2.0)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six==20221105->-r requirements.txt (line 5)) (41.0.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence-transformers->-r requirements.txt (line 7)) (4.65.0)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers->-r requirements.txt (line 7)) (2.0.1+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from sentence-transformers->-r requirements.txt (line 7)) (0.15.2+cu118)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers->-r requirements.txt (line 7)) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers->-r requirements.txt (line 7)) (1.10.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from sentence-transformers->-r requirements.txt (line 7)) (3.8.1)\n",
            "Collecting sentencepiece (from sentence-transformers->-r requirements.txt (line 7))\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->-r requirements.txt (line 9)) (3.12.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->-r requirements.txt (line 9)) (2023.6.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->-r requirements.txt (line 9)) (23.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 10)) (2022.10.31)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers->-r requirements.txt (line 10))\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m59.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers->-r requirements.txt (line 10))\n",
            "  Downloading safetensors-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m55.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting datasets (from auto-gptq->-r requirements.txt (line 14))\n",
            "  Downloading datasets-2.14.4-py3-none-any.whl (519 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m519.3/519.3 kB\u001b[0m \u001b[31m38.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rouge (from auto-gptq->-r requirements.txt (line 14))\n",
            "  Downloading rouge-1.0.1-py3-none-any.whl (13 kB)\n",
            "Collecting peft (from auto-gptq->-r requirements.txt (line 14))\n",
            "  Downloading peft-0.4.0-py3-none-any.whl (72 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.9/72.9 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate->-r requirements.txt (line 18)) (5.9.5)\n",
            "Requirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.10/dist-packages (from flask->-r requirements.txt (line 21)) (2.3.6)\n",
            "Requirement already satisfied: Jinja2>=3.0 in /usr/local/lib/python3.10/dist-packages (from flask->-r requirements.txt (line 21)) (3.1.2)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from flask->-r requirements.txt (line 21)) (2.1.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->-r requirements.txt (line 22)) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->-r requirements.txt (line 22)) (2023.7.22)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.10/dist-packages (from openpyxl->-r requirements.txt (line 25)) (1.1.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.191->-r requirements.txt (line 2)) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.191->-r requirements.txt (line 2)) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.191->-r requirements.txt (line 2)) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.191->-r requirements.txt (line 2)) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.191->-r requirements.txt (line 2)) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/lib/python3/dist-packages (from clickhouse-connect>=0.5.7->chromadb==0.3.22->-r requirements.txt (line 3)) (4.6.4)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.10/dist-packages (from clickhouse-connect>=0.5.7->chromadb==0.3.22->-r requirements.txt (line 3)) (2022.7.1)\n",
            "Collecting zstandard (from clickhouse-connect>=0.5.7->chromadb==0.3.22->-r requirements.txt (line 3))\n",
            "  Downloading zstandard-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m74.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting lz4 (from clickhouse-connect>=0.5.7->chromadb==0.3.22->-r requirements.txt (line 3))\n",
            "  Downloading lz4-4.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m64.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=36.0.0->pdfminer.six==20221105->-r requirements.txt (line 5)) (1.15.1)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.6.0,>=0.5.7->langchain==0.0.191->-r requirements.txt (line 2))\n",
            "  Downloading marshmallow-3.20.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.6.0,>=0.5.7->langchain==0.0.191->-r requirements.txt (line 2))\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Collecting starlette<0.28.0,>=0.27.0 (from fastapi>=0.85.1->chromadb==0.3.22->-r requirements.txt (line 3))\n",
            "  Downloading starlette-0.27.0-py3-none-any.whl (66 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=3.0->flask->-r requirements.txt (line 21)) (2.1.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.3->chromadb==0.3.22->-r requirements.txt (line 3)) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from posthog>=2.4.0->chromadb==0.3.22->-r requirements.txt (line 3)) (1.16.0)\n",
            "Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb==0.3.22->-r requirements.txt (line 3))\n",
            "  Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
            "Collecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb==0.3.22->-r requirements.txt (line 3))\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain==0.0.191->-r requirements.txt (line 2)) (2.0.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers->-r requirements.txt (line 7)) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers->-r requirements.txt (line 7)) (3.1)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers->-r requirements.txt (line 7)) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->sentence-transformers->-r requirements.txt (line 7)) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->sentence-transformers->-r requirements.txt (line 7)) (16.0.6)\n",
            "Collecting h11>=0.8 (from uvicorn[standard]>=0.18.3->chromadb==0.3.22->-r requirements.txt (line 3))\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httptools>=0.5.0 (from uvicorn[standard]>=0.18.3->chromadb==0.3.22->-r requirements.txt (line 3))\n",
            "  Downloading httptools-0.6.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (428 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m428.8/428.8 kB\u001b[0m \u001b[31m37.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-dotenv>=0.13 (from uvicorn[standard]>=0.18.3->chromadb==0.3.22->-r requirements.txt (line 3))\n",
            "  Downloading python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n",
            "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.18.3->chromadb==0.3.22->-r requirements.txt (line 3))\n",
            "  Downloading uvloop-0.17.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.1/4.1 MB\u001b[0m \u001b[31m73.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb==0.3.22->-r requirements.txt (line 3))\n",
            "  Downloading watchfiles-0.19.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m59.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting websockets>=10.4 (from uvicorn[standard]>=0.18.3->chromadb==0.3.22->-r requirements.txt (line 3))\n",
            "  Downloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->auto-gptq->-r requirements.txt (line 14)) (9.0.0)\n",
            "Collecting dill<0.3.8,>=0.3.0 (from datasets->auto-gptq->-r requirements.txt (line 14))\n",
            "  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting xxhash (from datasets->auto-gptq->-r requirements.txt (line 14))\n",
            "  Downloading xxhash-3.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m24.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets->auto-gptq->-r requirements.txt (line 14))\n",
            "  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->sentence-transformers->-r requirements.txt (line 7)) (1.3.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers->-r requirements.txt (line 7)) (3.2.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->sentence-transformers->-r requirements.txt (line 7)) (9.4.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20221105->-r requirements.txt (line 5)) (2.21)\n",
            "Requirement already satisfied: anyio<5,>=3.4.0 in /usr/local/lib/python3.10/dist-packages (from starlette<0.28.0,>=0.27.0->fastapi>=0.85.1->chromadb==0.3.22->-r requirements.txt (line 3)) (3.7.1)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain==0.0.191->-r requirements.txt (line 2))\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->sentence-transformers->-r requirements.txt (line 7)) (1.3.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette<0.28.0,>=0.27.0->fastapi>=0.85.1->chromadb==0.3.22->-r requirements.txt (line 3)) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette<0.28.0,>=0.27.0->fastapi>=0.85.1->chromadb==0.3.22->-r requirements.txt (line 3)) (1.1.2)\n",
            "Building wheels for collected packages: llama-cpp-python, sentence-transformers, auto-gptq, hnswlib\n",
            "  Building wheel for llama-cpp-python (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for llama-cpp-python: filename=llama_cpp_python-0.1.48-cp310-cp310-linux_x86_64.whl size=180725 sha256=7136e1e5b6bc5f19f6bfce44ec93b71627472798b61be667850a126dcd165b76\n",
            "  Stored in directory: /root/.cache/pip/wheels/eb/06/0e/6ae7b299ed252075128644d31384cac683e9fd768a8538c6be\n",
            "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125925 sha256=2bec662f5dd2f232e8111fdc4a8921ce76a1248641b6fbba04e0098552de73fc\n",
            "  Stored in directory: /root/.cache/pip/wheels/62/f2/10/1e606fd5f02395388f74e7462910fe851042f97238cbbd902f\n",
            "  Building wheel for auto-gptq (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for auto-gptq: filename=auto_gptq-0.3.0-cp310-cp310-linux_x86_64.whl size=5677353 sha256=891b54880e36cf3cb8ddb3686c20ea803edc4d6d032a0e9e5027869826c71225\n",
            "  Stored in directory: /root/.cache/pip/wheels/62/ca/da/632464db8c2071b514d3b659652383c789f53cc2fc917737bb\n",
            "  Building wheel for hnswlib (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for hnswlib: filename=hnswlib-0.7.0-cp310-cp310-linux_x86_64.whl size=2202562 sha256=583abc0ffb0da0064fa8722fcad8ae58657b46ca79eb6fdda7e73d00ff1ac605\n",
            "  Stored in directory: /root/.cache/pip/wheels/8a/ae/ec/235a682e0041fbaeee389843670581ec6c66872db856dfa9a4\n",
            "Successfully built llama-cpp-python sentence-transformers auto-gptq hnswlib\n",
            "Installing collected packages: tokenizers, sentencepiece, safetensors, monotonic, InstructorEmbedding, faiss-cpu, bitsandbytes, zstandard, xxhash, websockets, uvloop, urllib3, rouge, python-dotenv, protobuf, mypy-extensions, marshmallow, lz4, llama-cpp-python, httptools, hnswlib, h11, dill, backoff, watchfiles, uvicorn, typing-inspect, starlette, openapi-schema-pydantic, multiprocess, clickhouse-connect, posthog, pdfminer.six, huggingface_hub, fastapi, dataclasses-json, transformers, langchain, datasets, accelerate, sentence-transformers, peft, chromadb, auto-gptq\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.26.16\n",
            "    Uninstalling urllib3-1.26.16:\n",
            "      Successfully uninstalled urllib3-1.26.16\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.20.3\n",
            "    Uninstalling protobuf-3.20.3:\n",
            "      Successfully uninstalled protobuf-3.20.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-api-core 2.11.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0.dev0,>=3.19.5, but you have protobuf 3.20.0 which is incompatible.\n",
            "google-cloud-bigquery 3.10.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.0 which is incompatible.\n",
            "google-cloud-bigquery-connection 1.12.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.0 which is incompatible.\n",
            "google-cloud-bigquery-storage 2.22.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.0 which is incompatible.\n",
            "google-cloud-datastore 2.15.2 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.0 which is incompatible.\n",
            "google-cloud-firestore 2.11.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.0 which is incompatible.\n",
            "google-cloud-functions 1.13.2 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.0 which is incompatible.\n",
            "google-cloud-language 2.9.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.0 which is incompatible.\n",
            "google-cloud-translate 3.11.3 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.0 which is incompatible.\n",
            "googleapis-common-protos 1.60.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0.dev0,>=3.19.5, but you have protobuf 3.20.0 which is incompatible.\n",
            "grpc-google-iam-v1 0.12.6 requires protobuf!=3.20.0,!=3.20.1,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.0 which is incompatible.\n",
            "tensorflow 2.12.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 3.20.0 which is incompatible.\n",
            "tensorflow-metadata 1.13.1 requires protobuf<5,>=3.20.3, but you have protobuf 3.20.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed InstructorEmbedding-1.0.1 accelerate-0.21.0 auto-gptq-0.3.0 backoff-2.2.1 bitsandbytes-0.41.1 chromadb-0.3.22 clickhouse-connect-0.6.8 dataclasses-json-0.5.14 datasets-2.14.4 dill-0.3.7 faiss-cpu-1.7.4 fastapi-0.101.0 h11-0.14.0 hnswlib-0.7.0 httptools-0.6.0 huggingface_hub-0.16.4 langchain-0.0.191 llama-cpp-python-0.1.48 lz4-4.3.2 marshmallow-3.20.1 monotonic-1.6 multiprocess-0.70.15 mypy-extensions-1.0.0 openapi-schema-pydantic-1.2.4 pdfminer.six-20221105 peft-0.4.0 posthog-3.0.1 protobuf-3.20.0 python-dotenv-1.0.0 rouge-1.0.1 safetensors-0.3.2 sentence-transformers-2.2.2 sentencepiece-0.1.99 starlette-0.27.0 tokenizers-0.13.3 transformers-4.31.0 typing-inspect-0.9.0 urllib3-1.26.6 uvicorn-0.23.2 uvloop-0.17.0 watchfiles-0.19.0 websockets-11.0.3 xxhash-3.3.0 zstandard-0.21.0\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QoTqIGGDBRDw",
        "outputId": "62a932fa-2feb-4686-8e8d-29f77ed8bc43"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-08-10 11:49:44,607 - INFO - ingest.py:120 - Loading documents from /content/drive/MyDrive/Colab/localGPT/SOURCE_DOCUMENTS\n",
            "2023-08-10 11:49:44,621 - INFO - ingest.py:33 - Loading document batch\n",
            "2023-08-10 11:49:44,629 - INFO - ingest.py:33 - Loading document batch\n",
            "2023-08-10 11:50:54,046 - INFO - ingest.py:129 - Loaded 3 documents from /content/drive/MyDrive/Colab/localGPT/SOURCE_DOCUMENTS\n",
            "2023-08-10 11:50:54,046 - INFO - ingest.py:130 - Split into 2803 chunks of text\n",
            "2023-08-10 11:50:57,793 - INFO - SentenceTransformer.py:66 - Load pretrained SentenceTransformer: hkunlp/instructor-large\n",
            "Downloading (…)c7233/.gitattributes: 100% 1.48k/1.48k [00:00<00:00, 8.63MB/s]\n",
            "Downloading (…)_Pooling/config.json: 100% 270/270 [00:00<00:00, 1.57MB/s]\n",
            "Downloading (…)/2_Dense/config.json: 100% 116/116 [00:00<00:00, 700kB/s]\n",
            "Downloading pytorch_model.bin: 100% 3.15M/3.15M [00:00<00:00, 27.4MB/s]\n",
            "Downloading (…)9fb15c7233/README.md: 100% 66.3k/66.3k [00:00<00:00, 26.1MB/s]\n",
            "Downloading (…)b15c7233/config.json: 100% 1.53k/1.53k [00:00<00:00, 8.16MB/s]\n",
            "Downloading (…)ce_transformers.json: 100% 122/122 [00:00<00:00, 694kB/s]\n",
            "Downloading pytorch_model.bin: 100% 1.34G/1.34G [00:57<00:00, 23.3MB/s]\n",
            "Downloading (…)nce_bert_config.json: 100% 53.0/53.0 [00:00<00:00, 291kB/s]\n",
            "Downloading (…)cial_tokens_map.json: 100% 2.20k/2.20k [00:00<00:00, 11.6MB/s]\n",
            "Downloading spiece.model: 100% 792k/792k [00:00<00:00, 29.6MB/s]\n",
            "Downloading (…)c7233/tokenizer.json: 100% 2.42M/2.42M [00:00<00:00, 48.9MB/s]\n",
            "Downloading (…)okenizer_config.json: 100% 2.41k/2.41k [00:00<00:00, 12.0MB/s]\n",
            "Downloading (…)15c7233/modules.json: 100% 461/461 [00:00<00:00, 2.73MB/s]\n",
            "load INSTRUCTOR_Transformer\n",
            "2023-08-10 11:51:59,060 - INFO - instantiator.py:21 - Created a temporary directory at /tmp/tmpuumrv_vd\n",
            "2023-08-10 11:51:59,061 - INFO - instantiator.py:76 - Writing /tmp/tmpuumrv_vd/_remote_module_non_scriptable.py\n",
            "2023-08-10 11:52:00.711485: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "max_seq_length  512\n",
            "2023-08-10 11:52:07,611 - INFO - __init__.py:88 - Running Chroma using direct local API.\n",
            "2023-08-10 11:52:07,637 - WARNING - __init__.py:43 - Using embedded DuckDB with persistence: data will be stored in: /content/drive/MyDrive/Colab/localGPT/DB\n",
            "2023-08-10 11:52:07,650 - INFO - ctypes.py:22 - Successfully imported ClickHouse Connect C data optimizations\n",
            "2023-08-10 11:52:07,667 - INFO - json_impl.py:45 - Using python library for writing JSON byte strings\n",
            "2023-08-10 11:52:10,999 - INFO - duckdb.py:460 - loaded in 5966 embeddings\n",
            "2023-08-10 11:52:11,193 - INFO - duckdb.py:472 - loaded in 1 collections\n",
            "2023-08-10 11:52:11,195 - INFO - duckdb.py:89 - collection with name langchain already exists, returning existing collection\n",
            "2023-08-10 11:56:10,503 - INFO - duckdb.py:414 - Persisting DB to disk, putting it in the save folder: /content/drive/MyDrive/Colab/localGPT/DB\n",
            "2023-08-10 11:56:14,301 - INFO - duckdb.py:414 - Persisting DB to disk, putting it in the save folder: /content/drive/MyDrive/Colab/localGPT/DB\n"
          ]
        }
      ],
      "source": [
        "!python ingest.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gliDLF6dSN2G"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q_JCa45qEDSm",
        "outputId": "bf7c31dc-8f4e-47fb-aed3-90bea88cb3fd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-08-10 11:58:59.120541: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-08-10 11:59:04,261 - INFO - run_localGPT.py:161 - Running on: cuda\n",
            "2023-08-10 11:59:04,261 - INFO - run_localGPT.py:162 - Display Source Documents set to: False\n",
            "2023-08-10 11:59:04,479 - INFO - SentenceTransformer.py:66 - Load pretrained SentenceTransformer: hkunlp/instructor-large\n",
            "load INSTRUCTOR_Transformer\n",
            "max_seq_length  512\n",
            "2023-08-10 11:59:08,786 - INFO - __init__.py:88 - Running Chroma using direct local API.\n",
            "2023-08-10 11:59:08,799 - WARNING - __init__.py:43 - Using embedded DuckDB with persistence: data will be stored in: /content/drive/MyDrive/Colab/localGPT/DB\n",
            "2023-08-10 11:59:08,806 - INFO - ctypes.py:22 - Successfully imported ClickHouse Connect C data optimizations\n",
            "2023-08-10 11:59:08,814 - INFO - json_impl.py:45 - Using python library for writing JSON byte strings\n",
            "2023-08-10 11:59:09,283 - INFO - duckdb.py:460 - loaded in 8769 embeddings\n",
            "2023-08-10 11:59:09,288 - INFO - duckdb.py:472 - loaded in 1 collections\n",
            "2023-08-10 11:59:09,290 - INFO - duckdb.py:89 - collection with name langchain already exists, returning existing collection\n",
            "2023-08-10 11:59:09,290 - INFO - run_localGPT.py:43 - Loading Model: TheBloke/WizardLM-7B-uncensored-GPTQ, on: cuda\n",
            "2023-08-10 11:59:09,290 - INFO - run_localGPT.py:44 - This action can take a few minutes!\n",
            "2023-08-10 11:59:09,290 - INFO - run_localGPT.py:49 - Using AutoGPTQForCausalLM for quantized models\n",
            "Downloading (…)okenizer_config.json: 100% 727/727 [00:00<00:00, 4.25MB/s]\n",
            "Downloading tokenizer.model: 100% 500k/500k [00:00<00:00, 12.2MB/s]\n",
            "Downloading (…)/main/tokenizer.json: 100% 1.84M/1.84M [00:00<00:00, 24.0MB/s]\n",
            "Downloading (…)in/added_tokens.json: 100% 21.0/21.0 [00:00<00:00, 120kB/s]\n",
            "Downloading (…)cial_tokens_map.json: 100% 96.0/96.0 [00:00<00:00, 528kB/s]\n",
            "2023-08-10 11:59:10,230 - INFO - run_localGPT.py:56 - Tokenizer loaded\n",
            "Downloading (…)lve/main/config.json: 100% 552/552 [00:00<00:00, 2.25MB/s]\n",
            "Downloading (…)quantize_config.json: 100% 57.0/57.0 [00:00<00:00, 387kB/s]\n",
            "Downloading (…)ct-order.safetensors: 100% 3.89G/3.89G [01:04<00:00, 59.9MB/s]\n",
            "2023-08-10 12:00:15,842 - INFO - _base.py:746 - lm_head not been quantized, will be ignored when make_quant.\n",
            "2023-08-10 12:00:18,019 - WARNING - modeling.py:1093 - The safetensors archive passed at /root/.cache/huggingface/hub/models--TheBloke--WizardLM-7B-uncensored-GPTQ/snapshots/dcb3400039f15cff76b43a4921c59d47c5fc2252/WizardLM-7B-uncensored-GPTQ-4bit-128g.compat.no-act-order.safetensors does not contain metadata. Make sure to save your model with the `save_pretrained` method. Defaulting to 'pt' metadata.\n",
            "2023-08-10 12:00:47,287 - WARNING - fused_llama_mlp.py:280 - skip module injection for FusedLlamaMLPForQuantizedModel not support integrate without triton yet.\n",
            "Downloading (…)neration_config.json: 100% 137/137 [00:00<00:00, 757kB/s]\n",
            "Xformers is not installed correctly. If you want to use memory_efficient_attention to accelerate training use the following command to install Xformers\n",
            "pip install xformers.\n",
            "The model 'LlamaGPTQForCausalLM' is not supported for text-generation. Supported models are ['BartForCausalLM', 'BertLMHeadModel', 'BertGenerationDecoder', 'BigBirdForCausalLM', 'BigBirdPegasusForCausalLM', 'BioGptForCausalLM', 'BlenderbotForCausalLM', 'BlenderbotSmallForCausalLM', 'BloomForCausalLM', 'CamembertForCausalLM', 'CodeGenForCausalLM', 'CpmAntForCausalLM', 'CTRLLMHeadModel', 'Data2VecTextForCausalLM', 'ElectraForCausalLM', 'ErnieForCausalLM', 'FalconForCausalLM', 'GitForCausalLM', 'GPT2LMHeadModel', 'GPT2LMHeadModel', 'GPTBigCodeForCausalLM', 'GPTNeoForCausalLM', 'GPTNeoXForCausalLM', 'GPTNeoXJapaneseForCausalLM', 'GPTJForCausalLM', 'LlamaForCausalLM', 'MarianForCausalLM', 'MBartForCausalLM', 'MegaForCausalLM', 'MegatronBertForCausalLM', 'MusicgenForCausalLM', 'MvpForCausalLM', 'OpenLlamaForCausalLM', 'OpenAIGPTLMHeadModel', 'OPTForCausalLM', 'PegasusForCausalLM', 'PLBartForCausalLM', 'ProphetNetForCausalLM', 'QDQBertLMHeadModel', 'ReformerModelWithLMHead', 'RemBertForCausalLM', 'RobertaForCausalLM', 'RobertaPreLayerNormForCausalLM', 'RoCBertForCausalLM', 'RoFormerForCausalLM', 'RwkvForCausalLM', 'Speech2Text2ForCausalLM', 'TransfoXLLMHeadModel', 'TrOCRForCausalLM', 'XGLMForCausalLM', 'XLMWithLMHeadModel', 'XLMProphetNetForCausalLM', 'XLMRobertaForCausalLM', 'XLMRobertaXLForCausalLM', 'XLNetLMHeadModel', 'XmodForCausalLM'].\n",
            "2023-08-10 12:00:47,965 - INFO - run_localGPT.py:108 - Local LLM Loaded\n",
            "\n",
            "Enter a query: Write a php program that displays \"Very good weather outside\" if the temperature is between 10 and 30 degrees and the message \"Better stay indoors today\" otherwise.\n",
            "\n",
            "\n",
            "> Question:\n",
            "Write a php program that displays \"Very good weather outside\" if the temperature is between 10 and 30 degrees and the message \"Better stay indoors today\" otherwise.\n",
            "\n",
            "> Answer:\n",
            " Here's one way to write the program in PHP:\n",
            "```\n",
            "<?php\n",
            "$temp = 25; // current temperature in Celsius\n",
            "if ($temp >= 10 && $temp <= 30) {\n",
            "  echo \"Very good weather outside\";\n",
            "} else {\n",
            "  echo \"Better stay indoors today\";\n",
            "}\n",
            "?>\n",
            "```\n",
            "This program sets the variable `$temp` to the current temperature in Celsius, then uses an `if` statement to check if it's between 10 and 30 degrees. If it is, the program displays \"Very good weather outside\". Otherwise, it displays \"Better stay indoors today\". You can adjust the temperature threshold as needed.\n",
            "\n",
            "Enter a query:  Here's one way to write the program in PHP: ``` <?php $temp = 25; // current temperature in Celsius if ($temp >= 10 && $temp <= 30) {   echo \"Very good weather outside\"; } else {   echo \"Better stay indoors today\"; } ?> ``` This program sets the variable `$temp` to the current temperature in Celsius, then uses an `if` statement to check if it's between 10 and 30 degrees. If it is, the program displays \"Very good weather outside\". Otherwise, it displays \"Better stay indoors today\". You can adjust the temperature threshold as needed.  Rewrite the solution using the ternary operator.\n",
            "\n",
            "\n",
            "> Question:\n",
            " Here's one way to write the program in PHP: ``` <?php $temp = 25; // current temperature in Celsius if ($temp >= 10 && $temp <= 30) {   echo \"Very good weather outside\"; } else {   echo \"Better stay indoors today\"; } ?> ``` This program sets the variable `$temp` to the current temperature in Celsius, then uses an `if` statement to check if it's between 10 and 30 degrees. If it is, the program displays \"Very good weather outside\". Otherwise, it displays \"Better stay indoors today\". You can adjust the temperature threshold as needed.  Rewrite the solution using the ternary operator.\n",
            "\n",
            "> Answer:\n",
            "Here's how you can rewrite the same program using the ternary operator: ``` <?php $temp = 25; // current temperature in Celsius $out = \"Very good weather outside\"; if ($temp >= 10 && $temp <= 30) { $out = \"Better stay indoors today\"; }?> ``` In this version, the ternary operator (`?`) allows us to set two different expressions based on the temperature value. When the temperature is between 10 and 30 degrees, the program sets `$out` to \"Better stay indoors today\". Otherwise, it sets `$out` to \"Very good weather outside\".\n",
            "\n",
            "Enter a query: "
          ]
        }
      ],
      "source": [
        "!python run_localGPT.py"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "mount_file_id": "1mD8W3hEytLuMxcf4WlcnE6f1CyozgRZA",
      "authorship_tag": "ABX9TyMjW1ZWnmgF58+ChOjkzbpm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}